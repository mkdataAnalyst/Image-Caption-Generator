# Model Evaluation Notebook
from nltk.translate.bleu_score import corpus_bleu

# Assume we have actual and predicted captions
actual = [['<start> a dog is running <end>'.split()]]
predicted = ['<start> a dog is running <end>'.split()]

# BLEU Scores
print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))
print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))
print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))
print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))
